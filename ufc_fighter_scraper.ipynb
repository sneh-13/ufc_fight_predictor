{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import libraries\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d1eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Corrected function\n",
    "def get_soup(url, max_retries=3): # Changed parameter name to match logic below\n",
    "    # Defined headers dictionary\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # specific timeout ensures it doesn't hang indefinitely\n",
    "            response = requests.get(url, headers=headers, timeout=10) \n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print(f\"Success: Retrieved {url}\")\n",
    "                return BeautifulSoup(response.content, 'html.parser')\n",
    "            else:\n",
    "                print(f\"Warning: Status code {response.status_code} for {url}\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying... ({attempt + 1}/{max_retries})\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL you want to test\n",
    "test_url = \"http://ufcstats.com/statistics/fighters\"\n",
    "\n",
    "# 1. Call the function\n",
    "soup = get_soup(test_url)\n",
    "\n",
    "# 2. Verify the output\n",
    "if soup:\n",
    "    print(\"\\n--- TEST PASSED ---\")\n",
    "    print(f\"Object Type: {type(soup)}\")\n",
    "    \n",
    "    # 3. Check specific content to ensure it's the right page\n",
    "    # The title tag is usually the best quick check\n",
    "    page_title = soup.title.text.strip() if soup.title else \"No Title Found\"\n",
    "    print(f\"Page Title: '{page_title}'\")\n",
    "    \n",
    "    # 4. (Optional) Print the first 500 characters of HTML to see structure\n",
    "    print(\"\\n--- HTML PREVIEW (First 500 chars) ---\")\n",
    "    print(soup.prettify()[:500])\n",
    "else:\n",
    "    print(\"\\n--- TEST FAILED ---\")\n",
    "    print(\"The function returned None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4892777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_label(full_text, label_with_colon):\n",
    "    \"\"\"Remove a leading 'Label:' (case-insensitive) from 'Label: value'.\"\"\"\n",
    "    if not full_text:\n",
    "        return ''\n",
    "    pattern = r'^\\s*' + re.escape(label_with_colon) + r'\\s*'\n",
    "    return re.sub(pattern, '', full_text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text data\"\"\"\n",
    "    if text:\n",
    "        return re.sub(r'\\s+', ' ', text.strip())\n",
    "    return ''\n",
    "\n",
    "def parse_percentage(text):\n",
    "    \"\"\"Convert percentage text to float\"\"\"\n",
    "    if text and '%' in text:\n",
    "        return float(text.replace('%', '').strip())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ad7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get advanced fighter details from fighter's main page (ex.SLpM, Str. Acc., SApM, Str. Def., TD Avg., TD Acc., TD Def., Sub. Avg.)\n",
    "\n",
    "def get_fighter_advanced_details(fighter_url):\n",
    "    fighter_soup = get_soup(fighter_url)\n",
    "    if not fighter_soup:\n",
    "        print(f\"Failed to retrieve fighter page: {fighter_url}\")\n",
    "        return {}\n",
    "    \n",
    "    details = {}\n",
    "\n",
    "    # Get fighter bio information\n",
    "    bio_box = fighter_soup.find('div', class_='b-list__info-box')\n",
    "    if bio_box:\n",
    "        bio_items = bio_box.find_all('li', class_='b-list__box-list-item')\n",
    "        for item in bio_items:\n",
    "            label_tag = item.find('i')\n",
    "            if not label_tag:\n",
    "                continue\n",
    "\n",
    "            label_raw = clean_text(label_tag.text)          # e.g., 'DOB:'\n",
    "            label_key = label_raw.rstrip(':').lower()       # 'dob'\n",
    "\n",
    "            # Full text still includes the label; strip it out\n",
    "            value_full = clean_text(item.get_text(separator=' '))\n",
    "            value_only = strip_label(value_full, label_raw) # e.g., 'Jan 01, 1990'\n",
    "\n",
    "            if label_key == 'height':\n",
    "                details['height'] = value_only\n",
    "            elif label_key == 'weight':\n",
    "                details['weight'] = value_only\n",
    "            elif label_key == 'reach':\n",
    "                details['reach'] = value_only\n",
    "            elif label_key == 'stance':\n",
    "                details['stance'] = value_only\n",
    "            elif label_key == 'dob':\n",
    "                details['dob'] = value_only\n",
    "\n",
    "\n",
    "    \n",
    "    # Get career statistics\n",
    "    career_stats = fighter_soup.find_all('div', class_='b-list__info-box-left')\n",
    "    for stat_box in career_stats:\n",
    "        stat_items = stat_box.find_all('li', class_='b-list__box-list-item')\n",
    "        for item in stat_items:\n",
    "            label_elem = item.find('i')\n",
    "            if label_elem and label_elem.text:\n",
    "                label = clean_text(label_elem.text)\n",
    "                value = clean_text(item.text.replace(label, ''))\n",
    "                \n",
    "                if 'SLpM' in label:\n",
    "                    details['strikes_landed_per_min'] = value\n",
    "                elif 'Str. Acc' in label:\n",
    "                    details['striking_accuracy'] = value\n",
    "                elif 'SApM' in label:\n",
    "                    details['strikes_absorbed_per_min'] = value\n",
    "                elif 'Str. Def' in label:\n",
    "                    details['striking_defense'] = value\n",
    "                elif 'TD Avg' in label:\n",
    "                    details['takedown_avg'] = value\n",
    "                elif 'TD Acc' in label:\n",
    "                    details['takedown_accuracy'] = value\n",
    "                elif 'TD Def' in label:\n",
    "                    details['takedown_defense'] = value\n",
    "                elif 'Sub. Avg' in label:\n",
    "                    details['submission_avg'] = value\n",
    "    \n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Fighter Data\n",
    "\n",
    "def get_fighter_data(limit = None): \n",
    "    base_url = \"http://ufcstats.com/statistics/fighters\"\n",
    "    fighters_data = []\n",
    "    fighters_collected_count = 0\n",
    "\n",
    "    # Get all letter pages (a-z)\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        # OPTIMIZATION: If we hit the limit, stop checking other letters\n",
    "        if limit and fighters_collected_count >= limit:\n",
    "            break\n",
    "\n",
    "        letter_url = f\"{base_url}?char={letter}&page=all\"\n",
    "        print(f\"\\nScraping fighters starting with '{letter.upper()}' from {letter_url}\")\n",
    "    \n",
    "        soup = get_soup(letter_url)\n",
    "        if not soup:\n",
    "            print(f\"Failed to retrieve data for letter '{letter.upper()}'. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Find fighter table\n",
    "        table = soup.find('table', class_='b-statistics__table')\n",
    "        if not table:\n",
    "            continue\n",
    "        \n",
    "        rows = table.find_all('tr')[1:]  # Skip header row\n",
    "        \n",
    "        for row in rows:\n",
    "\n",
    "            # Stop Check 2: Check limit before processing each fighter\n",
    "            if limit and fighters_collected_count >= limit:\n",
    "                break\n",
    "\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= 10:\n",
    "                fighter_info = {\n",
    "                    'fighter_id': cols[0].find('a')['href'].split('/')[-1] if cols[0].find('a') else None,\n",
    "                    'firstname': clean_text(cols[0].text),\n",
    "                    'lastname' : clean_text(cols[1].text),\n",
    "                    'nickname': clean_text(cols[2].text),\n",
    "                    \n",
    "                    'wins': clean_text(cols[7].text),\n",
    "                    'losses': clean_text(cols[8].text),\n",
    "                    'draws': clean_text(cols[9].text),\n",
    "                }\n",
    "\n",
    "                # Get fighter url and parse additional details from fighters main page\n",
    "                fighter_url = f\"http://ufcstats.com/fighter-details/{fighter_info['fighter_id']}\"\n",
    "                fighter_details = get_fighter_advanced_details(fighter_url)\n",
    "                \n",
    "                fighter_full = {**fighter_info, **fighter_details}\n",
    "\n",
    "                all_fields = list(fighter_full.values())\n",
    "                \n",
    "                missing = any(field == \"\" or field == \"--\" for field in all_fields)\n",
    "                if missing:\n",
    "                    print(f\"Skipping incomplete data for fighter: {fighter_full}\") #can change to return first and last names\n",
    "                    continue\n",
    "\n",
    "                fighters_data.append(fighter_full)\n",
    "                fighters_collected_count += 1\n",
    "                time.sleep(0.5)\n",
    "        \n",
    "        # Be respectful with request rate\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(f\"Total fighters found: {len(fighters_data)}\")\n",
    "    return fighters_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b163f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scrape with a limit of 10\n",
    "data = get_fighter_data(limit=10)\n",
    "\n",
    "# Convert to pandas DataFrame to view clearly\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('fighter_stats_raw.csv', index=False)\n",
    "display(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean UFC fighter CSV -> numeric features to numeric types(except id/name fields)\n",
    "#\n",
    "#Variable Legend:\n",
    "#column name:               short:              Description:\n",
    "#fighter_id\t                fighter_id\t        Unique identifier for fighter (end of URL)\n",
    "#firstname\t                first_name\t        Fighter given name\t\n",
    "#lastname\t                last_name\t        Fighter family/surname\t\n",
    "#nickname\t                nickname\t        Fighter nickname/alias\t\n",
    "#wins\t                    wins\t            Official wins\t\n",
    "#losses\t                    losses\t            Official losses\t\n",
    "#draws\t                    draws           \tOfficial draws\t\n",
    "#height                 \theight\t            Stated height in inches\n",
    "#weight\t                    weight          \tStated weight in lb\n",
    "#reach\t                    reach\t            Arm reach in inches\n",
    "#stance\t                    stance\t            Primary fighting stance (e.g., Orthodox, Southpaw, Switch)\t\n",
    "#dob\t                    dob\t                Date of birth\tYYYY-MM-DD\n",
    "#strikes_landed_per_min\t    SLpM\t            Significant Strikes Landed per Minute\tstrikes/min\n",
    "#striking_accuracy\t        Str. Acc.\t        Significant Striking Accuracy\tpercent (0–100)\n",
    "#strikes_absorbed_per_min\tSApM\t            Significant Strikes Absorbed per Minute\tstrikes/min\n",
    "#striking_defense\t        Str. Def.\t        Significant Strike Defence (opponent strikes that did NOT land)\tpercent (0–100)\n",
    "#takedown_avg\t            TD Avg.\t            Average Takedowns Landed per 15 minutes\ttakedowns/15 min\n",
    "#takedown_accuracy\t        TD Acc.\t            Takedown Accuracy percent (0–100)\n",
    "#takedown_defense\t        TD Def.\t            Takedown Defence (opponent TD attempts that did NOT land)\tpercent (0–100)\n",
    "#submission_avg\t            Sub. Avg.\t        Average Submissions Attempted per 15 minutes\tsubs/15 min\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --------- CONFIG (edit these) ----------\n",
    "INPUT_CSV  = \"fighter_stats_raw.csv\"           # your source file\n",
    "OUTPUT_CSV = \"fighter_stats_cleaned.csv\"   # output file\n",
    "\n",
    "# stance mapping you requested: 0/1/2\n",
    "STANCE_MAP = {\"orthodox\": 0, \"southpaw\": 1, \"switch\": 2}\n",
    "\n",
    "# --------- HELPERS ----------\n",
    "def height_to_inches(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    t = str(s).strip().lower()\n",
    "    # 173 cm -> inches\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*cm', t)\n",
    "    if m: return float(m.group(1)) / 2.54\n",
    "    # 5' 8\", 5'8\", 5'8, 5 ft 8 in\n",
    "    m = re.search(r'(\\d+)\\s*(?:ft|feet)?\\s*[\\']\\s*(\\d+)\\s*(?:in|\")?', t)\n",
    "    if m: return float(m.group(1))*12 + float(m.group(2))\n",
    "    # 68\", 68 in\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(?:in|\")', t)\n",
    "    if m: return float(m.group(1))\n",
    "    # bare number => assume inches\n",
    "    m = re.search(r'^\\s*(\\d+(?:\\.\\d+)?)\\s*$', t)\n",
    "    if m: return float(m.group(1))\n",
    "    return np.nan\n",
    "\n",
    "def weight_to_lbs(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    t = str(s).strip().lower()\n",
    "    # 70 kg -> lb\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*kg', t)\n",
    "    if m: return float(m.group(1)) * 2.2046226218\n",
    "    # 155 lbs., 155 lb\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(?:lb|lbs|pounds)\\.?', t)\n",
    "    if m: return float(m.group(1))\n",
    "    # bare number => assume pounds\n",
    "    m = re.search(r'^\\s*(\\d+(?:\\.\\d+)?)\\s*$', t)\n",
    "    if m: return float(m.group(1))\n",
    "    return np.nan\n",
    "\n",
    "def reach_to_inches(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    t = str(s).strip().lower()\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*cm', t)\n",
    "    if m: return float(m.group(1)) / 2.54\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(?:in|\")', t)\n",
    "    if m: return float(m.group(1))\n",
    "    m = re.search(r'^\\s*(\\d+(?:\\.\\d+)?)\\s*$', t)  # bare number => inches\n",
    "    if m: return float(m.group(1))\n",
    "    return np.nan\n",
    "\n",
    "def extract_year(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    m = re.search(r'(\\d{4})', str(s))\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "\n",
    "def stance_to_code(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    return STANCE_MAP.get(str(s).strip().lower(), np.nan)  # unknown -> NaN\n",
    "\n",
    "def pct_to_float(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    return pd.to_numeric(str(s).replace('%','').strip(), errors='coerce')\n",
    "\n",
    "def to_float(s):\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "def find_col(df, candidates):\n",
    "    \"\"\"Return the first existing column matching any candidate (case-insensitive).\"\"\"\n",
    "    lut = {c.lower(): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        c = lut.get(cand.lower())\n",
    "        if c is not None:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# --------- LOAD ----------\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# --------- CONVERSIONS ----------\n",
    "# Height -> inches\n",
    "c = find_col(df, [\"height\"])\n",
    "if c: df[c] = df[c].apply(height_to_inches)\n",
    "\n",
    "# Weight -> pounds\n",
    "c = find_col(df, [\"weight\"])\n",
    "if c: df[c] = df[c].apply(weight_to_lbs)\n",
    "\n",
    "# Reach -> inches\n",
    "c = find_col(df, [\"reach\"])\n",
    "if c: df[c] = df[c].apply(reach_to_inches)\n",
    "\n",
    "# Stance -> 0/1/2\n",
    "c = find_col(df, [\"stance\"])\n",
    "if c: df[c] = df[c].apply(stance_to_code)\n",
    "\n",
    "# DOB -> year only\n",
    "c = find_col(df, [\"dob\", \"date_of_birth\", \"birthdate\"])\n",
    "if c: df[c] = df[c].apply(extract_year)\n",
    "\n",
    "# Percent columns (handle common typos too)\n",
    "for group in [\n",
    "    [\"striking_accuracy\", \"striking_accuarcy\"],\n",
    "    [\"striking_defense\", \"striking_defence\"],\n",
    "    [\"takedown_accuracy\"],\n",
    "    [\"takedown_defense\", \"takedown_defence\"],\n",
    "]:\n",
    "    c = find_col(df, group)\n",
    "    if c: df[c] = df[c].apply(pct_to_float)\n",
    "\n",
    "# Rate/average columns\n",
    "for group in [\n",
    "    [\"strikes_landed_per_min\"],\n",
    "    [\"strikes_absorbed_per_min\"],\n",
    "    [\"takedown_avg\", \"takedown_average\"],\n",
    "    [\"submission_avg\", \"submission_average\"],\n",
    "]:\n",
    "    c = find_col(df, group)\n",
    "    if c: df[c] = df[c].apply(to_float)\n",
    "\n",
    "# W/L/D\n",
    "for group in [[\"wins\"], [\"losses\"], [\"draws\"]]:\n",
    "    c = find_col(df, group)\n",
    "    if c: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# --------- ENFORCE: everything numeric except these 4 ----------\n",
    "keep_object = set()\n",
    "for opts in [[\"fighter_id\"], [\"firstname\", \"first_name\"], [\"lastname\", \"last_name\"], [\"nickname\"]]:\n",
    "    c = find_col(df, opts)\n",
    "    if c: keep_object.add(c)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in keep_object:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# --------- SAVE & REPORT ----------\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(\"Saved:\", OUTPUT_CSV)\n",
    "print(\"\\nNon-numeric columns kept as text:\", sorted(keep_object))\n",
    "print(df.dtypes.head(25))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
